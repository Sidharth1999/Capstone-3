{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xZxvYC0i8pjhcRyHs2L4Bc6teac2FFAI",
      "authorship_tag": "ABX9TyNkUEdQhhrme9b1GH2dZunq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidharth1999/Capstone-3/blob/main/Image_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpE3fSO6-CSm"
      },
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pathlib\n",
        "import imageio\n",
        "import functools\n",
        "import math\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pyzXj-FLufL"
      },
      "source": [
        "dataDir = \"/content/drive/My Drive/Springboard-Capstone-3/data\"\n",
        "projectDir = \"/content/drive/My Drive/Springboard-Capstone-3\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGOtMCT9RLKi"
      },
      "source": [
        "# **Download Dataset from Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "uhs4ipfhJMc1",
        "outputId": "8cee756b-a57f-4c88-9c50-665aa18aa724"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b966fe2-690d-44fc-89fe-3fc7c049393e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1b966fe2-690d-44fc-89fe-3fc7c049393e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"sidharthr1999\",\"key\":\"b06c0eb687ec8653837b4badf109296d\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y8ELj7UKvDe"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMi4RYmPK1az",
        "outputId": "4f898ea1-7ebf-427f-f923-df34177ba55e"
      },
      "source": [
        "# Verify that kaggle commands work\n",
        "! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              229KB  2021-06-01 11:18:46           6831  \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           4086  \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           1364  \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   1GB  2021-02-18 10:08:27           2128  \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            459  \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00            689  \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52            978  \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            698  \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            412  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            554  \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            146  \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            170  \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26             66  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40             84  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51             82  \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54             77  \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         141760  \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         137844  \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          23641  \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          18934  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w36rN7W2QMKf"
      },
      "source": [
        "dataset1 = \"iamsouravbanerjee/indian-food-images-dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iCYLqDmLnpY",
        "outputId": "01c26230-5c86-4ca4-9a68-d4979a1e725e"
      },
      "source": [
        "#Download dataset\n",
        "!kaggle datasets download $dataset1 -p \"$dataDir\" --unzip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading indian-food-images-dataset.zip to /content/drive/My Drive/Springboard-Capstone-3/data\n",
            " 97% 343M/354M [00:02<00:00, 128MB/s]\n",
            "100% 354M/354M [00:03<00:00, 123MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZR7rAdQRSK0"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6tfMKi4GsOr",
        "outputId": "da6a51be-fa5a-45d6-97f9-cf23ef010314"
      },
      "source": [
        "#Obtain all 80 categories\n",
        "categories = []\n",
        "for file in os.listdir(dataDir): categories.append(file)\n",
        "print(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['adhirasam', 'aloo_gobi', 'aloo_matar', 'aloo_methi', 'aloo_shimla_mirch', 'aloo_tikki', 'anarsa', 'ariselu', 'bandar_laddu', 'basundi', 'bhatura', 'bhindi_masala', 'biryani', 'boondi', 'butter_chicken', 'chak_hao_kheer', 'cham_cham', 'chana_masala', 'chapati', 'chhena_kheeri', 'chicken_razala', 'chicken_tikka', 'chicken_tikka_masala', 'chikki', 'daal_baati_churma', 'daal_puri', 'dal_makhani', 'dal_tadka', 'dharwad_pedha', 'doodhpak', 'double_ka_meetha', 'dum_aloo', 'gajar_ka_halwa', 'gavvalu', 'ghevar', 'gulab_jamun', 'imarti', 'jalebi', 'kachori', 'kadai_paneer', 'kadhi_pakoda', 'kajjikaya', 'kakinada_khaja', 'kalakand', 'karela_bharta', 'kofta', 'kuzhi_paniyaram', 'lassi', 'ledikeni', 'litti_chokha', 'lyangcha', 'maach_jhol', 'makki_di_roti_sarson_da_saag', 'malapua', 'misi_roti', 'misti_doi', 'modak', 'mysore_pak', 'naan', 'navrattan_korma', 'palak_paneer', 'paneer_butter_masala', 'phirni', 'pithe', 'poha', 'poornalu', 'pootharekulu', 'qubani_ka_meetha', 'rabri', 'ras_malai', 'rasgulla', 'sandesh', 'shankarpali', 'sheer_korma', 'sheera', 'shrikhand', 'sohan_halwa', 'sohan_papdi', 'sutar_feni', 'unni_appam']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so_AyIDaIjCt",
        "outputId": "2052a1ec-adbe-460e-bec9-a7b432d18c05"
      },
      "source": [
        "#Extract all 4000 image paths for each of the 80 categories\n",
        "def imagePathsFromCategory(category):\n",
        "  generator = pathlib.Path(dataDir + '/' + category).glob('*.jpg')\n",
        "  sorted_paths = sorted([x for x in generator])\n",
        "  return sorted_paths \n",
        "\n",
        "image_paths = [imagePathsFromCategory(category) for category in categories]\n",
        "\n",
        "#Confirm all 4000 image paths were extracted:\n",
        "print(functools.reduce(lambda a, b: a+b, [len(categoryPaths) for categoryPaths in image_paths]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bjY_u6wOuKo"
      },
      "source": [
        "#Split each of the 80 categories into train, validation, and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train = []\n",
        "validation = []\n",
        "test = []\n",
        "for i in range(len(image_paths)):\n",
        "  train_images, test_images, _, _ = train_test_split(image_paths[i], range(len(image_paths[i])), test_size=0.20, random_state=42)\n",
        "  train_images, validation_images, _, _ = train_test_split(train_images, range(len(train_images)), test_size=0.20, random_state=42)\n",
        "  train.append(train_images)\n",
        "  validation.append(validation_images)\n",
        "  test.append(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC1HsNuP79_u"
      },
      "source": [
        "#Make separate directories for each set\n",
        "os.mkdir(os.path.join(projectDir, \"train\"))\n",
        "os.mkdir(os.path.join(projectDir, \"validation\"))\n",
        "os.mkdir(os.path.join(projectDir, \"test\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5qytGwTbcK8"
      },
      "source": [
        "trainDir = projectDir + \"/\" + \"train\"\n",
        "validationDir = projectDir + \"/\" + \"validation\"\n",
        "testDir = projectDir + \"/\" + \"test\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdbvQkh2Vnrz"
      },
      "source": [
        "#Insert data from each category into the newly created train, validation, and test folders\n",
        "for i in range(len(categories)):\n",
        "  category = categories[i]\n",
        "  train_set = train[i]\n",
        "  validation_set = validation[i]\n",
        "  test_set = test[i]\n",
        "  trainDestDir = os.path.join(trainDir, category)\n",
        "  valDestDir = os.path.join(validationDir, category)\n",
        "  testDestDir = os.path.join(testDir, category)\n",
        "  os.mkdir(trainDestDir)\n",
        "  os.mkdir(valDestDir)\n",
        "  os.mkdir(testDestDir)\n",
        "\n",
        "  for j in range(len(train_set)):\n",
        "    impath = os.path.join(trainDestDir, f'image{j}.jpg')\n",
        "    imageio.imwrite(impath, imageio.imread(train_set[j]))\n",
        "\n",
        "  for j in range(len(validation_set)):\n",
        "    impath = os.path.join(valDestDir, f'image{j}.jpg')\n",
        "    imageio.imwrite(impath, imageio.imread(validation_set[j]))\n",
        "\n",
        "  for j in range(len(test_set)):\n",
        "    impath = os.path.join(testDestDir, f'image{j}.jpg')\n",
        "    imageio.imwrite(impath, imageio.imread(test_set[j]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYAdEqnYJnhs"
      },
      "source": [
        "# **Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yXbyJaXJuej"
      },
      "source": [
        "**Potential Configurable Parameters:**\n",
        "\n",
        "1.   Train/Dev/Test split-ratio\n",
        "2.   Number of layers\n",
        "3.   Number of nodes per layer\n",
        "4.   Optimizer\n",
        "5.   Learning rate of optimizer\n",
        "6.   Target image size\n",
        "7.   Generator morphological transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD4OtTc9Kcw0"
      },
      "source": [
        "**We are going to try 4 different CNN architectures:**\n",
        "\n",
        "\n",
        "1.   VGG16\n",
        "2.   DenseNet201\n",
        "3.   ResNet50\n",
        "4.   InceptionV3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzUcQaNYr_L4"
      },
      "source": [
        "#Make a directory to save different CNN model features\n",
        "cnnFeaturesDir = os.path.join(projectDir, 'CNN Architecture Features')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTRK5zOcsC5U"
      },
      "source": [
        "os.mkdir(cnnFeaturesDir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5VUFZpmJSq4"
      },
      "source": [
        "## **VGG-16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os05870cypgt",
        "outputId": "efad9e10-00b6-47a9-cac4-54b5a3c0b95e"
      },
      "source": [
        "#Build data generators\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import vgg16\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function = vgg16.preprocess_input,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function = vgg16.preprocess_input,\n",
        "    rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        trainDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validationDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        testDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2560 images belonging to 80 classes.\n",
            "Found 640 images belonging to 80 classes.\n",
            "Found 800 images belonging to 80 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emhv1X-tMtV4"
      },
      "source": [
        "### **Transfer Learning Method #1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFcoSaHCy71-"
      },
      "source": [
        "#OHE for the labels\n",
        "trainTarget = to_categorical(train_generator.labels)\n",
        "valTarget = to_categorical(validation_generator.labels)\n",
        "\n",
        "#Import model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "vggModel = VGG16(include_top=False, weights='imagenet')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50Z1r0bQZ0_b"
      },
      "source": [
        "#Extract VGG16 Features - RUN ONLY ONCE AND THEN SAVE\n",
        "vggTrainFeatures = vggModel.predict(train_generator)\n",
        "vggValFeatures = vggModel.predict(validation_generator)\n",
        "np.save(cnnFeaturesDir + '/' + 'VGG16-train-features.npy', vggTrainFeatures)\n",
        "np.save(cnnFeaturesDir + '/' + 'VGG16-val-features.npy', vggValFeatures)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sphJa8_Emc1C",
        "outputId": "2b9ebb7d-6253-4aba-d145-8bc09df9a45a"
      },
      "source": [
        "#Retrieve features from project directory\n",
        "vggTrainData = np.load(cnnFeaturesDir + '/' + 'VGG16-train-features.npy')\n",
        "vggValData = np.load(cnnFeaturesDir + '/' + 'VGG16-val-features.npy')\n",
        "\n",
        "#Structure, compile and train the VGG16 model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, LeakyReLU\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Flatten(input_shape=vggTrainData.shape[1:]))\n",
        "model1.add(Dense(100, activation=LeakyReLU(alpha=0.3)))\n",
        "model1.add(Dropout(0.5)) \n",
        "model1.add(Dense(50, activation=LeakyReLU(alpha=0.3))) \n",
        "model1.add(Dropout(0.3)) \n",
        "model1.add(Dense(80, activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4), metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "\n",
        "history = model1.fit(vggTrainData,\n",
        "                     trainTarget,\n",
        "                     epochs=50,\n",
        "                     batch_size=32,\n",
        "                     validation_data=(vggValData, valTarget))\n",
        "\n",
        "(eval_loss, eval_accuracy) = model1.evaluate(vggValData, valTarget, batch_size=32, verbose=1)\n",
        "print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"Loss: {}\".format(eval_loss))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "80/80 [==============================] - 1s 4ms/step - loss: 4.5009 - accuracy: 0.0094 - val_loss: 4.4038 - val_accuracy: 0.0141\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.4500 - accuracy: 0.0129 - val_loss: 4.3970 - val_accuracy: 0.0172\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.4322 - accuracy: 0.0152 - val_loss: 4.3941 - val_accuracy: 0.0125\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.4288 - accuracy: 0.0117 - val_loss: 4.3936 - val_accuracy: 0.0141\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.4063 - accuracy: 0.0121 - val_loss: 4.3918 - val_accuracy: 0.0156\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.4081 - accuracy: 0.0117 - val_loss: 4.3910 - val_accuracy: 0.0125\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3996 - accuracy: 0.0141 - val_loss: 4.3898 - val_accuracy: 0.0078\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3953 - accuracy: 0.0125 - val_loss: 4.3897 - val_accuracy: 0.0078\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3898 - accuracy: 0.0137 - val_loss: 4.3900 - val_accuracy: 0.0109\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3858 - accuracy: 0.0133 - val_loss: 4.3898 - val_accuracy: 0.0125\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3882 - accuracy: 0.0129 - val_loss: 4.3888 - val_accuracy: 0.0125\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3863 - accuracy: 0.0148 - val_loss: 4.3891 - val_accuracy: 0.0094\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3787 - accuracy: 0.0172 - val_loss: 4.3900 - val_accuracy: 0.0094\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3744 - accuracy: 0.0215 - val_loss: 4.3904 - val_accuracy: 0.0078\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3736 - accuracy: 0.0160 - val_loss: 4.3906 - val_accuracy: 0.0094\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3644 - accuracy: 0.0223 - val_loss: 4.3908 - val_accuracy: 0.0141\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3692 - accuracy: 0.0223 - val_loss: 4.3910 - val_accuracy: 0.0141\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3649 - accuracy: 0.0188 - val_loss: 4.3923 - val_accuracy: 0.0203\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3595 - accuracy: 0.0211 - val_loss: 4.3924 - val_accuracy: 0.0125\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3615 - accuracy: 0.0191 - val_loss: 4.3921 - val_accuracy: 0.0141\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3553 - accuracy: 0.0289 - val_loss: 4.3932 - val_accuracy: 0.0141\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3555 - accuracy: 0.0215 - val_loss: 4.3936 - val_accuracy: 0.0125\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3496 - accuracy: 0.0219 - val_loss: 4.3933 - val_accuracy: 0.0156\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3497 - accuracy: 0.0234 - val_loss: 4.3935 - val_accuracy: 0.0125\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3457 - accuracy: 0.0250 - val_loss: 4.3939 - val_accuracy: 0.0172\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3409 - accuracy: 0.0215 - val_loss: 4.3938 - val_accuracy: 0.0125\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3393 - accuracy: 0.0246 - val_loss: 4.3946 - val_accuracy: 0.0125\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3316 - accuracy: 0.0246 - val_loss: 4.3957 - val_accuracy: 0.0094\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3347 - accuracy: 0.0340 - val_loss: 4.3951 - val_accuracy: 0.0125\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3291 - accuracy: 0.0312 - val_loss: 4.3964 - val_accuracy: 0.0125\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3252 - accuracy: 0.0262 - val_loss: 4.3979 - val_accuracy: 0.0125\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3253 - accuracy: 0.0320 - val_loss: 4.3979 - val_accuracy: 0.0125\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3227 - accuracy: 0.0281 - val_loss: 4.3977 - val_accuracy: 0.0125\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3160 - accuracy: 0.0281 - val_loss: 4.3990 - val_accuracy: 0.0109\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3113 - accuracy: 0.0301 - val_loss: 4.3990 - val_accuracy: 0.0094\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3152 - accuracy: 0.0285 - val_loss: 4.4001 - val_accuracy: 0.0125\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3150 - accuracy: 0.0289 - val_loss: 4.3995 - val_accuracy: 0.0125\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3027 - accuracy: 0.0273 - val_loss: 4.4016 - val_accuracy: 0.0078\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3024 - accuracy: 0.0301 - val_loss: 4.4019 - val_accuracy: 0.0094\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3003 - accuracy: 0.0316 - val_loss: 4.4029 - val_accuracy: 0.0094\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.3043 - accuracy: 0.0246 - val_loss: 4.4032 - val_accuracy: 0.0109\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2937 - accuracy: 0.0367 - val_loss: 4.4042 - val_accuracy: 0.0109\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2932 - accuracy: 0.0340 - val_loss: 4.4047 - val_accuracy: 0.0078\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2901 - accuracy: 0.0340 - val_loss: 4.4067 - val_accuracy: 0.0094\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2839 - accuracy: 0.0375 - val_loss: 4.4067 - val_accuracy: 0.0063\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2773 - accuracy: 0.0426 - val_loss: 4.4079 - val_accuracy: 0.0109\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2859 - accuracy: 0.0336 - val_loss: 4.4075 - val_accuracy: 0.0109\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2761 - accuracy: 0.0281 - val_loss: 4.4083 - val_accuracy: 0.0109\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2747 - accuracy: 0.0324 - val_loss: 4.4098 - val_accuracy: 0.0109\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 4.2699 - accuracy: 0.0344 - val_loss: 4.4107 - val_accuracy: 0.0094\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 4.4107 - accuracy: 0.0094\n",
            "Accuracy: 0.94%\n",
            "Loss: 4.4106831550598145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-DYQlVYM1xx"
      },
      "source": [
        "### **Transfer Learning Method #2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBw4h7jFbOg5",
        "outputId": "24fb6bfa-c080-4828-b36c-7c4a17bcba95"
      },
      "source": [
        "vggModel = tf.keras.applications.VGG16(input_shape=(40,40,3),include_top=False,weights='imagenet')\n",
        "fine_tune = 1\n",
        "if fine_tune > 0:\n",
        "  for layer in vggModel.layers[:-fine_tune]: layer.trainable = False\n",
        "else:\n",
        "  for layer in vggModel.layers: layer.trainable = False\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(40, 40, 3))\n",
        "x = vggModel(inputs, training=False)\n",
        "'''x = tf.keras.layers.GlobalAveragePooling2D()(x)'''\n",
        "x = tf.keras.layers.Flatten(name=\"flatten\")(x)\n",
        "x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1072, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(80, activation='softmax')(x)\n",
        "\n",
        "model1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model1.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=int(math.ceil(train_generator.n/train_generator.batch_size)),\n",
        "    validation_steps=int(math.ceil(validation_generator.n/validation_generator.batch_size)))\n",
        "\n",
        "(eval_loss, eval_accuracy) = model1.evaluate(validation_generator, verbose=1)\n",
        "print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"Loss: {}\".format(eval_loss))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "80/80 [==============================] - 29s 352ms/step - loss: 4.3565 - accuracy: 0.0285 - val_loss: 4.0971 - val_accuracy: 0.0516\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 28s 351ms/step - loss: 3.9181 - accuracy: 0.0809 - val_loss: 3.7973 - val_accuracy: 0.1031\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 28s 352ms/step - loss: 3.6160 - accuracy: 0.1145 - val_loss: 3.6947 - val_accuracy: 0.1156\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 28s 354ms/step - loss: 3.3515 - accuracy: 0.1625 - val_loss: 3.6411 - val_accuracy: 0.1359\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 28s 349ms/step - loss: 3.1610 - accuracy: 0.2047 - val_loss: 3.5970 - val_accuracy: 0.1437\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 28s 346ms/step - loss: 2.9430 - accuracy: 0.2449 - val_loss: 3.5065 - val_accuracy: 0.1562\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 28s 348ms/step - loss: 2.7504 - accuracy: 0.2840 - val_loss: 3.6355 - val_accuracy: 0.1594\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 28s 347ms/step - loss: 2.6028 - accuracy: 0.3172 - val_loss: 3.5952 - val_accuracy: 0.1797\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 28s 351ms/step - loss: 2.4158 - accuracy: 0.3570 - val_loss: 3.6572 - val_accuracy: 0.1656\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 28s 350ms/step - loss: 2.2635 - accuracy: 0.4008 - val_loss: 3.6176 - val_accuracy: 0.2000\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 28s 352ms/step - loss: 2.0918 - accuracy: 0.4344 - val_loss: 3.6637 - val_accuracy: 0.1953\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 28s 349ms/step - loss: 1.9217 - accuracy: 0.4742 - val_loss: 3.6317 - val_accuracy: 0.2094\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 28s 346ms/step - loss: 1.7866 - accuracy: 0.5168 - val_loss: 3.7884 - val_accuracy: 0.2078\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 28s 345ms/step - loss: 1.6592 - accuracy: 0.5496 - val_loss: 3.8457 - val_accuracy: 0.2094\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 28s 350ms/step - loss: 1.5026 - accuracy: 0.5844 - val_loss: 3.8953 - val_accuracy: 0.2344\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 28s 348ms/step - loss: 1.4006 - accuracy: 0.5984 - val_loss: 4.0113 - val_accuracy: 0.2359\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 28s 349ms/step - loss: 1.2451 - accuracy: 0.6418 - val_loss: 4.0837 - val_accuracy: 0.2313\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 27s 344ms/step - loss: 1.1646 - accuracy: 0.6715 - val_loss: 4.0463 - val_accuracy: 0.2359\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 27s 345ms/step - loss: 1.1104 - accuracy: 0.6879 - val_loss: 4.2190 - val_accuracy: 0.2313\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 28s 345ms/step - loss: 1.0145 - accuracy: 0.7137 - val_loss: 4.3142 - val_accuracy: 0.2453\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 28s 344ms/step - loss: 0.9292 - accuracy: 0.7363 - val_loss: 4.2584 - val_accuracy: 0.2422\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 28s 344ms/step - loss: 0.8595 - accuracy: 0.7559 - val_loss: 4.4354 - val_accuracy: 0.2484\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 27s 345ms/step - loss: 0.7455 - accuracy: 0.7937 - val_loss: 4.4392 - val_accuracy: 0.2500\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 27s 344ms/step - loss: 0.7134 - accuracy: 0.7980 - val_loss: 4.5538 - val_accuracy: 0.2359\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 27s 343ms/step - loss: 0.6468 - accuracy: 0.8059 - val_loss: 4.7601 - val_accuracy: 0.2344\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 28s 349ms/step - loss: 0.6305 - accuracy: 0.8207 - val_loss: 4.8465 - val_accuracy: 0.2297\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 27s 344ms/step - loss: 0.6296 - accuracy: 0.8223 - val_loss: 4.6714 - val_accuracy: 0.2469\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 27s 345ms/step - loss: 0.5208 - accuracy: 0.8535 - val_loss: 4.8439 - val_accuracy: 0.2391\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 28s 345ms/step - loss: 0.5174 - accuracy: 0.8445 - val_loss: 5.0536 - val_accuracy: 0.2344\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 28s 346ms/step - loss: 0.5124 - accuracy: 0.8523 - val_loss: 4.9829 - val_accuracy: 0.2469\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 28s 344ms/step - loss: 0.4023 - accuracy: 0.8910 - val_loss: 5.2225 - val_accuracy: 0.2359\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 28s 343ms/step - loss: 0.4531 - accuracy: 0.8660 - val_loss: 5.1882 - val_accuracy: 0.2453\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 27s 345ms/step - loss: 0.4188 - accuracy: 0.8816 - val_loss: 5.1334 - val_accuracy: 0.2484\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 27s 343ms/step - loss: 0.3818 - accuracy: 0.8898 - val_loss: 5.3182 - val_accuracy: 0.2469\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 27s 344ms/step - loss: 0.3764 - accuracy: 0.8859 - val_loss: 5.1991 - val_accuracy: 0.2578\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 27s 342ms/step - loss: 0.3899 - accuracy: 0.8891 - val_loss: 5.2074 - val_accuracy: 0.2594\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 28s 346ms/step - loss: 0.3280 - accuracy: 0.9105 - val_loss: 5.3884 - val_accuracy: 0.2516\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 28s 345ms/step - loss: 0.3100 - accuracy: 0.9102 - val_loss: 5.3532 - val_accuracy: 0.2516\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 27s 344ms/step - loss: 0.2957 - accuracy: 0.9152 - val_loss: 5.4167 - val_accuracy: 0.2516\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 27s 344ms/step - loss: 0.2960 - accuracy: 0.9137 - val_loss: 5.5889 - val_accuracy: 0.2531\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 27s 346ms/step - loss: 0.2863 - accuracy: 0.9117 - val_loss: 5.5189 - val_accuracy: 0.2547\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 27s 345ms/step - loss: 0.3005 - accuracy: 0.9105 - val_loss: 5.6255 - val_accuracy: 0.2500\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 28s 343ms/step - loss: 0.2826 - accuracy: 0.9176 - val_loss: 5.4476 - val_accuracy: 0.2531\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 28s 345ms/step - loss: 0.2553 - accuracy: 0.9266 - val_loss: 5.7928 - val_accuracy: 0.2516\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 27s 342ms/step - loss: 0.2500 - accuracy: 0.9352 - val_loss: 5.6563 - val_accuracy: 0.2547\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 27s 345ms/step - loss: 0.2332 - accuracy: 0.9305 - val_loss: 5.6333 - val_accuracy: 0.2641\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 28s 342ms/step - loss: 0.2073 - accuracy: 0.9434 - val_loss: 5.8513 - val_accuracy: 0.2453\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 28s 345ms/step - loss: 0.2306 - accuracy: 0.9367 - val_loss: 5.6633 - val_accuracy: 0.2594\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 28s 343ms/step - loss: 0.2460 - accuracy: 0.9254 - val_loss: 5.9861 - val_accuracy: 0.2406\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 28s 346ms/step - loss: 0.2042 - accuracy: 0.9363 - val_loss: 5.8581 - val_accuracy: 0.2641\n",
            "20/20 [==============================] - 5s 236ms/step - loss: 5.8581 - accuracy: 0.2641\n",
            "Accuracy: 26.41%\n",
            "Loss: 5.858149528503418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEZtHh-yXvjP"
      },
      "source": [
        "### **Prediction Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45q7Ll3FXy0q",
        "outputId": "8205e7ed-39dc-4583-af3f-ef17733aeb5f"
      },
      "source": [
        "results = model1.evaluate(test_generator, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 6s 253ms/step - loss: 5.9049 - accuracy: 0.2512\n",
            "test loss, test acc: [5.9049482345581055, 0.2512499988079071]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rc3rUTMHoKc"
      },
      "source": [
        "model1.save(projectDir + '/' + 'Models/VGG16ModelV1.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQmWvaxgK3Ep"
      },
      "source": [
        "## **DenseNet201**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cekhb3Rf3dmW",
        "outputId": "5d7848c9-0fb5-402f-bde5-b1730a02a652"
      },
      "source": [
        "#Build data generators\n",
        "from tensorflow.keras.applications import densenet\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function = densenet.preprocess_input,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function = densenet.preprocess_input,\n",
        "    rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        trainDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validationDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        testDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2560 images belonging to 80 classes.\n",
            "Found 640 images belonging to 80 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK6CNxqZNVNu"
      },
      "source": [
        "### **Transfer Learning Method #1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_-W6EyB3eko"
      },
      "source": [
        "trainTarget = to_categorical(train_generator.labels)\n",
        "valTarget = to_categorical(validation_generator.labels)\n",
        "\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "DN201Model = DenseNet201(include_top=False, weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX901ZgQqHp5"
      },
      "source": [
        "DN201TrainFeatures = DN201Model.predict(train_generator, batch_size=32, steps=int(math.ceil(train_generator.n/train_generator.batch_size)))\n",
        "DN201ValFeatures = DN201Model.predict(validation_generator, batch_size=32, steps=int(math.ceil(validation_generator.n/validation_generator.batch_size)))\n",
        "np.save(cnnFeaturesDir + '/' + 'DN201-train-features.npy', DN201TrainFeatures)\n",
        "np.save(cnnFeaturesDir + '/' + 'DN201-val-features.npy', DN201ValFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abqK7bFkqgvM"
      },
      "source": [
        "DN201TrainData = np.load(cnnFeaturesDir + '/' + 'DN201-train-features.npy')\n",
        "DN201ValData = np.load(cnnFeaturesDir + '/' + 'DN201-val-features.npy')\n",
        "\n",
        "#Structure, compile and train the DenseNet201 model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, LeakyReLU\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Flatten(input_shape=DN201TrainData.shape[1:]))\n",
        "model2.add(Dense(100, activation=LeakyReLU(alpha=0.3)))\n",
        "model2.add(Dropout(0.5)) \n",
        "model2.add(Dense(100, activation=LeakyReLU(alpha=0.3))) \n",
        "model2.add(Dropout(0.3)) \n",
        "model2.add(Dense(80, activation='softmax'))\n",
        "\n",
        "model2.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "\n",
        "history = model2.fit(DN201TrainData,\n",
        "                     trainTarget,\n",
        "                     epochs=50,\n",
        "                     batch_size=32,\n",
        "                     validation_data=(DN201ValData, valTarget))\n",
        "\n",
        "(eval_loss, eval_accuracy) = model2.evaluate(DN201ValData, valTarget, batch_size=32, verbose=1)\n",
        "print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"Loss: {}\".format(eval_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ynKj-6rNZ1h"
      },
      "source": [
        "### **Transfer Learning Method #2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKKE3vRJ6qeO",
        "outputId": "d0131205-b59c-44b0-edf0-9dde2175ba48"
      },
      "source": [
        "DN201Model = tf.keras.applications.DenseNet201(input_shape=(40,40,3),include_top=False,weights='imagenet')\n",
        "DN201Model.trainable = False\n",
        "inputs = tf.keras.Input(shape=(40, 40, 3))\n",
        "x = DN201Model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = tf.keras.layers.Dense(80, activation='softmax')(x)\n",
        "\n",
        "model2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model2.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model2.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=int(math.ceil(train_generator.n/train_generator.batch_size)),\n",
        "    validation_steps=int(math.ceil(validation_generator.n/validation_generator.batch_size)))\n",
        "\n",
        "(eval_loss, eval_accuracy) = model2.evaluate(validation_generator, verbose=1)\n",
        "print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"Loss: {}\".format(eval_loss))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 2s 0us/step\n",
            "Epoch 1/20\n",
            "80/80 [==============================] - 54s 509ms/step - loss: 4.4745 - accuracy: 0.0102 - val_loss: 4.4029 - val_accuracy: 0.0141\n",
            "Epoch 2/20\n",
            "80/80 [==============================] - 38s 470ms/step - loss: 4.4078 - accuracy: 0.0203 - val_loss: 4.3803 - val_accuracy: 0.0234\n",
            "Epoch 3/20\n",
            "80/80 [==============================] - 37s 467ms/step - loss: 4.3831 - accuracy: 0.0156 - val_loss: 4.3700 - val_accuracy: 0.0141\n",
            "Epoch 4/20\n",
            "80/80 [==============================] - 37s 466ms/step - loss: 4.3613 - accuracy: 0.0211 - val_loss: 4.3529 - val_accuracy: 0.0125\n",
            "Epoch 5/20\n",
            "80/80 [==============================] - 37s 468ms/step - loss: 4.3333 - accuracy: 0.0254 - val_loss: 4.3503 - val_accuracy: 0.0234\n",
            "Epoch 6/20\n",
            "80/80 [==============================] - 37s 468ms/step - loss: 4.3194 - accuracy: 0.0230 - val_loss: 4.3260 - val_accuracy: 0.0328\n",
            "Epoch 7/20\n",
            "80/80 [==============================] - 37s 468ms/step - loss: 4.2956 - accuracy: 0.0324 - val_loss: 4.3325 - val_accuracy: 0.0375\n",
            "Epoch 8/20\n",
            "80/80 [==============================] - 37s 464ms/step - loss: 4.2857 - accuracy: 0.0293 - val_loss: 4.3051 - val_accuracy: 0.0250\n",
            "Epoch 9/20\n",
            "80/80 [==============================] - 37s 464ms/step - loss: 4.2596 - accuracy: 0.0320 - val_loss: 4.3074 - val_accuracy: 0.0266\n",
            "Epoch 10/20\n",
            "80/80 [==============================] - 37s 469ms/step - loss: 4.2564 - accuracy: 0.0320 - val_loss: 4.2876 - val_accuracy: 0.0422\n",
            "Epoch 11/20\n",
            "80/80 [==============================] - 37s 467ms/step - loss: 4.2307 - accuracy: 0.0395 - val_loss: 4.2883 - val_accuracy: 0.0281\n",
            "Epoch 12/20\n",
            "80/80 [==============================] - 37s 465ms/step - loss: 4.2166 - accuracy: 0.0422 - val_loss: 4.2770 - val_accuracy: 0.0359\n",
            "Epoch 13/20\n",
            "80/80 [==============================] - 37s 464ms/step - loss: 4.2177 - accuracy: 0.0418 - val_loss: 4.2751 - val_accuracy: 0.0359\n",
            "Epoch 14/20\n",
            "80/80 [==============================] - 37s 466ms/step - loss: 4.1966 - accuracy: 0.0434 - val_loss: 4.2741 - val_accuracy: 0.0359\n",
            "Epoch 15/20\n",
            "80/80 [==============================] - 37s 464ms/step - loss: 4.1872 - accuracy: 0.0500 - val_loss: 4.2595 - val_accuracy: 0.0375\n",
            "Epoch 16/20\n",
            "80/80 [==============================] - 37s 463ms/step - loss: 4.1705 - accuracy: 0.0574 - val_loss: 4.2656 - val_accuracy: 0.0328\n",
            "Epoch 17/20\n",
            "80/80 [==============================] - 37s 465ms/step - loss: 4.1671 - accuracy: 0.0523 - val_loss: 4.2580 - val_accuracy: 0.0344\n",
            "Epoch 18/20\n",
            "80/80 [==============================] - 37s 466ms/step - loss: 4.1470 - accuracy: 0.0543 - val_loss: 4.2491 - val_accuracy: 0.0312\n",
            "Epoch 19/20\n",
            "80/80 [==============================] - 37s 464ms/step - loss: 4.1354 - accuracy: 0.0504 - val_loss: 4.2452 - val_accuracy: 0.0281\n",
            "Epoch 20/20\n",
            "80/80 [==============================] - 37s 465ms/step - loss: 4.1288 - accuracy: 0.0562 - val_loss: 4.2525 - val_accuracy: 0.0437\n",
            "20/20 [==============================] - 7s 333ms/step - loss: 4.2525 - accuracy: 0.0437\n",
            "Accuracy: 4.37%\n",
            "Loss: 4.252532005310059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hbNSB2tYC5L"
      },
      "source": [
        "### **Prediction Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmfKKFsZYFEi"
      },
      "source": [
        "results = model2.evaluate(test_generator, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIeds2QyK79p"
      },
      "source": [
        "## **ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_-oCPUn4ZQB",
        "outputId": "4c66109f-3b27-4778-f440-f733e5059659"
      },
      "source": [
        "#Build data generators\n",
        "from tensorflow.keras.applications import resnet\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function = resnet.preprocess_input,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function = resnet.preprocess_input,\n",
        "    rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        trainDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validationDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        testDir,\n",
        "        target_size=(40, 40),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2560 images belonging to 80 classes.\n",
            "Found 640 images belonging to 80 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ_S_3bPNu13"
      },
      "source": [
        "### **Transfer Learning Method #1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUPumJfU4Z1S"
      },
      "source": [
        "trainTarget = to_categorical(train_generator.labels)\n",
        "valTarget = to_categorical(validation_generator.labels)\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "RN50Model = ResNet50(include_top=False, weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHCeU252s9SI"
      },
      "source": [
        "RN50TrainFeatures = RN50Model.predict(train_generator, batch_size=32, steps=int(math.ceil(train_generator.n/train_generator.batch_size)))\n",
        "RN50ValFeatures = RN50Model.predict(validation_generator, batch_size=32, steps=int(math.ceil(validation_generator.n/validation_generator.batch_size)))\n",
        "np.save(cnnFeaturesDir + '/' + 'RN50-train-features.npy', RN50TrainFeatures)\n",
        "np.save(cnnFeaturesDir + '/' + 'RN50-val-features.npy', RN50ValFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM0XMJmFtEeS"
      },
      "source": [
        "RN50TrainData = np.load(cnnFeaturesDir + '/' + 'RN50-train-features.npy')\n",
        "RN50ValData = np.load(cnnFeaturesDir + '/' + 'RN50-val-features.npy')\n",
        "\n",
        "#Structure, compile and train the ResNet50 model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, LeakyReLU\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Flatten(input_shape=RN50TrainData.shape[1:]))\n",
        "model3.add(Dense(100, activation=LeakyReLU(alpha=0.3)))\n",
        "model3.add(Dropout(0.5)) \n",
        "model3.add(Dense(100, activation=LeakyReLU(alpha=0.3))) \n",
        "model3.add(Dropout(0.3)) \n",
        "model3.add(Dense(80, activation='softmax'))\n",
        "\n",
        "model3.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "\n",
        "history = model3.fit(RN50TrainData,\n",
        "                     trainTarget,\n",
        "                     epochs=50,\n",
        "                     batch_size=32,\n",
        "                     validation_data=(RN50ValData, valTarget))\n",
        "\n",
        "(eval_loss, eval_accuracy) = model3.evaluate(RN50ValData, valTarget, batch_size=32, verbose=1)\n",
        "print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"Loss: {}\".format(eval_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTpzfmdxNzfV"
      },
      "source": [
        "### **Transfer Learning Method #2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A4y1AtN7LrF",
        "outputId": "0003b363-77dc-4de0-d44e-c0c410ebcda4"
      },
      "source": [
        "RN50Model = tf.keras.applications.ResNet50(input_shape=(40,40,3),include_top=False,weights='imagenet')\n",
        "RN50Model.trainable = False\n",
        "inputs = tf.keras.Input(shape=(40, 40, 3))\n",
        "x = RN50Model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = tf.keras.layers.Dense(80, activation='softmax')(x)\n",
        "\n",
        "model3 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model3.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model3.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=int(math.ceil(train_generator.n/train_generator.batch_size)),\n",
        "    validation_steps=int(math.ceil(validation_generator.n/validation_generator.batch_size)))\n",
        "\n",
        "(eval_loss, eval_accuracy) = model3.evaluate(validation_generator, verbose=1)\n",
        "print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"Loss: {}\".format(eval_loss))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/20\n",
            "80/80 [==============================] - 41s 462ms/step - loss: 4.4475 - accuracy: 0.0086 - val_loss: 4.3856 - val_accuracy: 0.0141\n",
            "Epoch 2/20\n",
            "80/80 [==============================] - 36s 449ms/step - loss: 4.4109 - accuracy: 0.0125 - val_loss: 4.3843 - val_accuracy: 0.0125\n",
            "Epoch 3/20\n",
            "80/80 [==============================] - 36s 443ms/step - loss: 4.3990 - accuracy: 0.0117 - val_loss: 4.3722 - val_accuracy: 0.0203\n",
            "Epoch 4/20\n",
            "80/80 [==============================] - 35s 443ms/step - loss: 4.3835 - accuracy: 0.0188 - val_loss: 4.3614 - val_accuracy: 0.0188\n",
            "Epoch 5/20\n",
            "80/80 [==============================] - 35s 441ms/step - loss: 4.3750 - accuracy: 0.0172 - val_loss: 4.3543 - val_accuracy: 0.0219\n",
            "Epoch 6/20\n",
            "80/80 [==============================] - 35s 443ms/step - loss: 4.3687 - accuracy: 0.0160 - val_loss: 4.3528 - val_accuracy: 0.0234\n",
            "Epoch 7/20\n",
            "80/80 [==============================] - 35s 442ms/step - loss: 4.3575 - accuracy: 0.0281 - val_loss: 4.3475 - val_accuracy: 0.0234\n",
            "Epoch 8/20\n",
            "80/80 [==============================] - 35s 443ms/step - loss: 4.3482 - accuracy: 0.0242 - val_loss: 4.3424 - val_accuracy: 0.0234\n",
            "Epoch 9/20\n",
            "80/80 [==============================] - 35s 443ms/step - loss: 4.3409 - accuracy: 0.0238 - val_loss: 4.3340 - val_accuracy: 0.0266\n",
            "Epoch 10/20\n",
            "80/80 [==============================] - 35s 444ms/step - loss: 4.3363 - accuracy: 0.0254 - val_loss: 4.3307 - val_accuracy: 0.0203\n",
            "Epoch 11/20\n",
            "80/80 [==============================] - 36s 443ms/step - loss: 4.3217 - accuracy: 0.0266 - val_loss: 4.3301 - val_accuracy: 0.0250\n",
            "Epoch 12/20\n",
            "80/80 [==============================] - 36s 448ms/step - loss: 4.3180 - accuracy: 0.0234 - val_loss: 4.3211 - val_accuracy: 0.0234\n",
            "Epoch 13/20\n",
            "80/80 [==============================] - 36s 448ms/step - loss: 4.3094 - accuracy: 0.0359 - val_loss: 4.3185 - val_accuracy: 0.0344\n",
            "Epoch 14/20\n",
            "80/80 [==============================] - 36s 447ms/step - loss: 4.3050 - accuracy: 0.0273 - val_loss: 4.3134 - val_accuracy: 0.0312\n",
            "Epoch 15/20\n",
            "80/80 [==============================] - 36s 447ms/step - loss: 4.2907 - accuracy: 0.0312 - val_loss: 4.3100 - val_accuracy: 0.0328\n",
            "Epoch 16/20\n",
            "80/80 [==============================] - 36s 447ms/step - loss: 4.2871 - accuracy: 0.0281 - val_loss: 4.3116 - val_accuracy: 0.0312\n",
            "Epoch 17/20\n",
            "80/80 [==============================] - 35s 441ms/step - loss: 4.2860 - accuracy: 0.0375 - val_loss: 4.3078 - val_accuracy: 0.0281\n",
            "Epoch 18/20\n",
            "80/80 [==============================] - 35s 444ms/step - loss: 4.2765 - accuracy: 0.0367 - val_loss: 4.2998 - val_accuracy: 0.0312\n",
            "Epoch 19/20\n",
            "80/80 [==============================] - 35s 439ms/step - loss: 4.2680 - accuracy: 0.0328 - val_loss: 4.2988 - val_accuracy: 0.0297\n",
            "Epoch 20/20\n",
            "80/80 [==============================] - 35s 443ms/step - loss: 4.2629 - accuracy: 0.0363 - val_loss: 4.2961 - val_accuracy: 0.0297\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 4.2961 - accuracy: 0.0297\n",
            "Accuracy: 2.97%\n",
            "Loss: 4.296078681945801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nLcFpjCYIIK"
      },
      "source": [
        "### **Prediction Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNYLS_CBYKuY"
      },
      "source": [
        "results = model3.evaluate(test_generator, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJP6lkQ5OKx9"
      },
      "source": [
        "## **InceptionV3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do12nLJVOOJZ",
        "outputId": "d11afc56-2708-430b-a6d7-07fd9a3b04fe"
      },
      "source": [
        "#Build data generators\n",
        "from tensorflow.keras.applications import inception_v3\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function = inception_v3.preprocess_input,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function = inception_v3.preprocess_input,\n",
        "    rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        trainDir,\n",
        "        target_size=(75, 75),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validationDir,\n",
        "        target_size=(75, 75),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        testDir,\n",
        "        target_size=(75, 75),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2560 images belonging to 80 classes.\n",
            "Found 640 images belonging to 80 classes.\n",
            "Found 800 images belonging to 80 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HscM2bpDOSBW"
      },
      "source": [
        "### **Transfer Learning Method #1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bElIWSw-OVRh"
      },
      "source": [
        "trainTarget = to_categorical(train_generator.labels)\n",
        "valTarget = to_categorical(validation_generator.labels)\n",
        "\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "IV3Model = InceptionV3(include_top=False, weights='imagenet')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7GfyK77OYke",
        "outputId": "64b785f4-c3bc-425c-eba6-006bc42e16ae"
      },
      "source": [
        "train_generator_2 = train_datagen.flow_from_directory(\n",
        "        trainDir,\n",
        "        target_size=(75, 75),\n",
        "        batch_size=32,\n",
        "        class_mode=None)\n",
        "validation_generator_2 = test_datagen.flow_from_directory(\n",
        "        validationDir,\n",
        "        target_size=(75, 75),\n",
        "        batch_size=32,\n",
        "        class_mode=None)\n",
        "\n",
        "IV3TrainFeatures = IV3Model.predict(train_generator_2, batch_size=32, steps=int(math.ceil(train_generator_2.n/train_generator_2.batch_size)))\n",
        "IV3ValFeatures = IV3Model.predict(validation_generator_2, batch_size=32, steps=int(math.ceil(validation_generator_2.n/validation_generator_2.batch_size)))\n",
        "np.save(cnnFeaturesDir + '/' + 'IV3-train-features.npy', IV3TrainFeatures)\n",
        "np.save(cnnFeaturesDir + '/' + 'IV3-val-features.npy', IV3ValFeatures)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2560 images belonging to 80 classes.\n",
            "Found 640 images belonging to 80 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7SDB0toOa3b",
        "outputId": "4ac16f7a-b221-40cb-8936-f95503f88ad1"
      },
      "source": [
        "IV3TrainData = np.load(cnnFeaturesDir + '/' + 'IV3-train-features.npy')\n",
        "IV3ValData = np.load(cnnFeaturesDir + '/' + 'IV3-val-features.npy')\n",
        "\n",
        "#Structure, compile and train the IV3 model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, LeakyReLU\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Flatten(input_shape=IV3TrainData.shape[1:]))\n",
        "model4.add(Dense(100, activation=LeakyReLU(alpha=0.3)))\n",
        "model4.add(Dropout(0.5)) \n",
        "model4.add(Dense(100, activation=LeakyReLU(alpha=0.3))) \n",
        "model4.add(Dropout(0.3)) \n",
        "model4.add(Dense(80, activation='softmax'))\n",
        "\n",
        "model4.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "\n",
        "history = model4.fit(IV3TrainData,\n",
        "                     trainTarget,\n",
        "                     epochs=100,\n",
        "                     batch_size=32,\n",
        "                     validation_data=(IV3ValData, valTarget))\n",
        "\n",
        "(eval_loss, eval_accuracy) = model4.evaluate(IV3ValData, valTarget, batch_size=32, verbose=1)\n",
        "print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"Loss: {}\".format(eval_loss))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 4.5553 - accuracy: 0.0102 - val_loss: 4.4036 - val_accuracy: 0.0125\n",
            "Epoch 2/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.4519 - accuracy: 0.0137 - val_loss: 4.4011 - val_accuracy: 0.0141\n",
            "Epoch 3/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.4561 - accuracy: 0.0152 - val_loss: 4.4006 - val_accuracy: 0.0125\n",
            "Epoch 4/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.4588 - accuracy: 0.0098 - val_loss: 4.3961 - val_accuracy: 0.0109\n",
            "Epoch 5/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.4244 - accuracy: 0.0160 - val_loss: 4.3993 - val_accuracy: 0.0172\n",
            "Epoch 6/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.4469 - accuracy: 0.0113 - val_loss: 4.3927 - val_accuracy: 0.0141\n",
            "Epoch 7/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.4261 - accuracy: 0.0168 - val_loss: 4.3994 - val_accuracy: 0.0156\n",
            "Epoch 8/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.4295 - accuracy: 0.0152 - val_loss: 4.3982 - val_accuracy: 0.0125\n",
            "Epoch 9/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.4099 - accuracy: 0.0141 - val_loss: 4.3935 - val_accuracy: 0.0125\n",
            "Epoch 10/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.4160 - accuracy: 0.0137 - val_loss: 4.3970 - val_accuracy: 0.0188\n",
            "Epoch 11/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.4161 - accuracy: 0.0129 - val_loss: 4.3939 - val_accuracy: 0.0188\n",
            "Epoch 12/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.3962 - accuracy: 0.0145 - val_loss: 4.4002 - val_accuracy: 0.0234\n",
            "Epoch 13/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.4048 - accuracy: 0.0195 - val_loss: 4.4054 - val_accuracy: 0.0125\n",
            "Epoch 14/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.3894 - accuracy: 0.0176 - val_loss: 4.4133 - val_accuracy: 0.0094\n",
            "Epoch 15/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.3887 - accuracy: 0.0184 - val_loss: 4.4127 - val_accuracy: 0.0094\n",
            "Epoch 16/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3908 - accuracy: 0.0184 - val_loss: 4.4436 - val_accuracy: 0.0172\n",
            "Epoch 17/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3853 - accuracy: 0.0172 - val_loss: 4.4165 - val_accuracy: 0.0125\n",
            "Epoch 18/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3775 - accuracy: 0.0250 - val_loss: 4.4384 - val_accuracy: 0.0078\n",
            "Epoch 19/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.3828 - accuracy: 0.0184 - val_loss: 4.4371 - val_accuracy: 0.0156\n",
            "Epoch 20/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.3745 - accuracy: 0.0172 - val_loss: 4.4427 - val_accuracy: 0.0203\n",
            "Epoch 21/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3740 - accuracy: 0.0238 - val_loss: 4.4413 - val_accuracy: 0.0156\n",
            "Epoch 22/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3637 - accuracy: 0.0238 - val_loss: 4.4320 - val_accuracy: 0.0063\n",
            "Epoch 23/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.3627 - accuracy: 0.0211 - val_loss: 4.4560 - val_accuracy: 0.0172\n",
            "Epoch 24/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3603 - accuracy: 0.0238 - val_loss: 4.4508 - val_accuracy: 0.0063\n",
            "Epoch 25/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3439 - accuracy: 0.0281 - val_loss: 4.4964 - val_accuracy: 0.0109\n",
            "Epoch 26/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3388 - accuracy: 0.0281 - val_loss: 4.4434 - val_accuracy: 0.0156\n",
            "Epoch 27/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3381 - accuracy: 0.0281 - val_loss: 4.4858 - val_accuracy: 0.0109\n",
            "Epoch 28/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3245 - accuracy: 0.0273 - val_loss: 4.4383 - val_accuracy: 0.0078\n",
            "Epoch 29/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3417 - accuracy: 0.0277 - val_loss: 4.4718 - val_accuracy: 0.0063\n",
            "Epoch 30/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3144 - accuracy: 0.0266 - val_loss: 4.4757 - val_accuracy: 0.0109\n",
            "Epoch 31/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3191 - accuracy: 0.0262 - val_loss: 4.4889 - val_accuracy: 0.0141\n",
            "Epoch 32/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3114 - accuracy: 0.0266 - val_loss: 4.4456 - val_accuracy: 0.0156\n",
            "Epoch 33/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3036 - accuracy: 0.0273 - val_loss: 4.5079 - val_accuracy: 0.0078\n",
            "Epoch 34/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3066 - accuracy: 0.0328 - val_loss: 4.4855 - val_accuracy: 0.0078\n",
            "Epoch 35/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.3034 - accuracy: 0.0305 - val_loss: 4.4800 - val_accuracy: 0.0125\n",
            "Epoch 36/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2909 - accuracy: 0.0305 - val_loss: 4.4806 - val_accuracy: 0.0125\n",
            "Epoch 37/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2867 - accuracy: 0.0301 - val_loss: 4.5316 - val_accuracy: 0.0141\n",
            "Epoch 38/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.2911 - accuracy: 0.0266 - val_loss: 4.5689 - val_accuracy: 0.0141\n",
            "Epoch 39/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2829 - accuracy: 0.0320 - val_loss: 4.4757 - val_accuracy: 0.0141\n",
            "Epoch 40/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2932 - accuracy: 0.0309 - val_loss: 4.5291 - val_accuracy: 0.0125\n",
            "Epoch 41/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2572 - accuracy: 0.0383 - val_loss: 4.4872 - val_accuracy: 0.0063\n",
            "Epoch 42/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2737 - accuracy: 0.0379 - val_loss: 4.4981 - val_accuracy: 0.0125\n",
            "Epoch 43/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.2782 - accuracy: 0.0352 - val_loss: 4.4895 - val_accuracy: 0.0094\n",
            "Epoch 44/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2605 - accuracy: 0.0340 - val_loss: 4.5043 - val_accuracy: 0.0156\n",
            "Epoch 45/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2667 - accuracy: 0.0336 - val_loss: 4.5192 - val_accuracy: 0.0094\n",
            "Epoch 46/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.2507 - accuracy: 0.0359 - val_loss: 4.5377 - val_accuracy: 0.0172\n",
            "Epoch 47/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2521 - accuracy: 0.0383 - val_loss: 4.5164 - val_accuracy: 0.0203\n",
            "Epoch 48/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2344 - accuracy: 0.0395 - val_loss: 4.5483 - val_accuracy: 0.0156\n",
            "Epoch 49/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.2226 - accuracy: 0.0359 - val_loss: 4.5043 - val_accuracy: 0.0172\n",
            "Epoch 50/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2222 - accuracy: 0.0426 - val_loss: 4.5448 - val_accuracy: 0.0094\n",
            "Epoch 51/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2059 - accuracy: 0.0465 - val_loss: 4.5897 - val_accuracy: 0.0172\n",
            "Epoch 52/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2471 - accuracy: 0.0324 - val_loss: 4.6283 - val_accuracy: 0.0047\n",
            "Epoch 53/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2197 - accuracy: 0.0465 - val_loss: 4.6013 - val_accuracy: 0.0063\n",
            "Epoch 54/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2224 - accuracy: 0.0484 - val_loss: 4.6028 - val_accuracy: 0.0125\n",
            "Epoch 55/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2082 - accuracy: 0.0445 - val_loss: 4.6064 - val_accuracy: 0.0109\n",
            "Epoch 56/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.2003 - accuracy: 0.0484 - val_loss: 4.6639 - val_accuracy: 0.0078\n",
            "Epoch 57/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1810 - accuracy: 0.0488 - val_loss: 4.6079 - val_accuracy: 0.0141\n",
            "Epoch 58/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1890 - accuracy: 0.0441 - val_loss: 4.6153 - val_accuracy: 0.0078\n",
            "Epoch 59/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1990 - accuracy: 0.0449 - val_loss: 4.5473 - val_accuracy: 0.0156\n",
            "Epoch 60/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1793 - accuracy: 0.0457 - val_loss: 4.6058 - val_accuracy: 0.0125\n",
            "Epoch 61/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1889 - accuracy: 0.0508 - val_loss: 4.5781 - val_accuracy: 0.0063\n",
            "Epoch 62/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1782 - accuracy: 0.0492 - val_loss: 4.7181 - val_accuracy: 0.0094\n",
            "Epoch 63/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1509 - accuracy: 0.0516 - val_loss: 4.7600 - val_accuracy: 0.0109\n",
            "Epoch 64/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1502 - accuracy: 0.0531 - val_loss: 4.6592 - val_accuracy: 0.0188\n",
            "Epoch 65/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1673 - accuracy: 0.0523 - val_loss: 4.7166 - val_accuracy: 0.0141\n",
            "Epoch 66/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.1616 - accuracy: 0.0508 - val_loss: 4.6212 - val_accuracy: 0.0094\n",
            "Epoch 67/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1461 - accuracy: 0.0539 - val_loss: 4.7580 - val_accuracy: 0.0078\n",
            "Epoch 68/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1547 - accuracy: 0.0539 - val_loss: 4.7126 - val_accuracy: 0.0063\n",
            "Epoch 69/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1273 - accuracy: 0.0516 - val_loss: 4.6192 - val_accuracy: 0.0109\n",
            "Epoch 70/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1275 - accuracy: 0.0609 - val_loss: 4.6658 - val_accuracy: 0.0125\n",
            "Epoch 71/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1385 - accuracy: 0.0527 - val_loss: 4.6452 - val_accuracy: 0.0109\n",
            "Epoch 72/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1137 - accuracy: 0.0531 - val_loss: 4.6649 - val_accuracy: 0.0094\n",
            "Epoch 73/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.1195 - accuracy: 0.0551 - val_loss: 4.7366 - val_accuracy: 0.0078\n",
            "Epoch 74/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1273 - accuracy: 0.0602 - val_loss: 4.7058 - val_accuracy: 0.0109\n",
            "Epoch 75/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 4.1097 - accuracy: 0.0668 - val_loss: 4.7313 - val_accuracy: 0.0094\n",
            "Epoch 76/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.1187 - accuracy: 0.0512 - val_loss: 4.7360 - val_accuracy: 0.0109\n",
            "Epoch 77/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0927 - accuracy: 0.0570 - val_loss: 4.8199 - val_accuracy: 0.0141\n",
            "Epoch 78/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0915 - accuracy: 0.0570 - val_loss: 4.6882 - val_accuracy: 0.0125\n",
            "Epoch 79/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0954 - accuracy: 0.0531 - val_loss: 4.7132 - val_accuracy: 0.0078\n",
            "Epoch 80/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0909 - accuracy: 0.0629 - val_loss: 4.6522 - val_accuracy: 0.0078\n",
            "Epoch 81/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0885 - accuracy: 0.0637 - val_loss: 4.6990 - val_accuracy: 0.0125\n",
            "Epoch 82/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0773 - accuracy: 0.0609 - val_loss: 4.7669 - val_accuracy: 0.0156\n",
            "Epoch 83/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0716 - accuracy: 0.0660 - val_loss: 4.8108 - val_accuracy: 0.0141\n",
            "Epoch 84/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0697 - accuracy: 0.0617 - val_loss: 4.7631 - val_accuracy: 0.0156\n",
            "Epoch 85/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0844 - accuracy: 0.0609 - val_loss: 4.7678 - val_accuracy: 0.0125\n",
            "Epoch 86/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0625 - accuracy: 0.0637 - val_loss: 4.7555 - val_accuracy: 0.0094\n",
            "Epoch 87/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0410 - accuracy: 0.0707 - val_loss: 4.8063 - val_accuracy: 0.0156\n",
            "Epoch 88/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0543 - accuracy: 0.0652 - val_loss: 4.6976 - val_accuracy: 0.0141\n",
            "Epoch 89/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0372 - accuracy: 0.0719 - val_loss: 4.7711 - val_accuracy: 0.0109\n",
            "Epoch 90/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0310 - accuracy: 0.0695 - val_loss: 4.7492 - val_accuracy: 0.0141\n",
            "Epoch 91/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0461 - accuracy: 0.0625 - val_loss: 4.8051 - val_accuracy: 0.0109\n",
            "Epoch 92/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0066 - accuracy: 0.0758 - val_loss: 4.8491 - val_accuracy: 0.0125\n",
            "Epoch 93/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0369 - accuracy: 0.0688 - val_loss: 4.7196 - val_accuracy: 0.0109\n",
            "Epoch 94/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0243 - accuracy: 0.0656 - val_loss: 4.7911 - val_accuracy: 0.0109\n",
            "Epoch 95/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0099 - accuracy: 0.0738 - val_loss: 4.8566 - val_accuracy: 0.0109\n",
            "Epoch 96/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0183 - accuracy: 0.0699 - val_loss: 4.7702 - val_accuracy: 0.0125\n",
            "Epoch 97/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0155 - accuracy: 0.0793 - val_loss: 4.8583 - val_accuracy: 0.0172\n",
            "Epoch 98/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0086 - accuracy: 0.0652 - val_loss: 4.8414 - val_accuracy: 0.0078\n",
            "Epoch 99/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 4.0079 - accuracy: 0.0785 - val_loss: 4.8122 - val_accuracy: 0.0172\n",
            "Epoch 100/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 3.9904 - accuracy: 0.0699 - val_loss: 4.8627 - val_accuracy: 0.0094\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 4.8627 - accuracy: 0.0094\n",
            "Accuracy: 0.94%\n",
            "Loss: 4.862685680389404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSWCI7TeOeZD"
      },
      "source": [
        "### **Transfer Learning Method #2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThseEBT2OhXH",
        "outputId": "986f9a61-98eb-44af-85d1-dcfd21058365"
      },
      "source": [
        "IV3Model = tf.keras.applications.InceptionV3(input_shape=(75,75,3),include_top=False,weights='imagenet')\n",
        "IV3Model.trainable = False\n",
        "inputs = tf.keras.Input(shape=(75, 75, 3))\n",
        "x = IV3Model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = tf.keras.layers.Dense(80, activation='softmax')(x)\n",
        "\n",
        "model4 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model4.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model4.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=int(math.ceil(train_generator.n/train_generator.batch_size)),\n",
        "    validation_steps=int(math.ceil(validation_generator.n/validation_generator.batch_size)))\n",
        "\n",
        "(eval_loss, eval_accuracy) = model4.evaluate(validation_generator, verbose=1)\n",
        "print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"Loss: {}\".format(eval_loss))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Epoch 1/30\n",
            "80/80 [==============================] - 66s 771ms/step - loss: 4.6490 - accuracy: 0.0133 - val_loss: 4.5731 - val_accuracy: 0.0141\n",
            "Epoch 2/30\n",
            "80/80 [==============================] - 64s 797ms/step - loss: 4.4894 - accuracy: 0.0188 - val_loss: 4.4576 - val_accuracy: 0.0266\n",
            "Epoch 3/30\n",
            "80/80 [==============================] - 60s 751ms/step - loss: 4.4007 - accuracy: 0.0270 - val_loss: 4.3458 - val_accuracy: 0.0344\n",
            "Epoch 4/30\n",
            "80/80 [==============================] - 61s 767ms/step - loss: 4.3144 - accuracy: 0.0316 - val_loss: 4.3199 - val_accuracy: 0.0453\n",
            "Epoch 5/30\n",
            "80/80 [==============================] - 62s 769ms/step - loss: 4.2712 - accuracy: 0.0383 - val_loss: 4.3209 - val_accuracy: 0.0266\n",
            "Epoch 6/30\n",
            "80/80 [==============================] - 63s 791ms/step - loss: 4.2157 - accuracy: 0.0492 - val_loss: 4.3222 - val_accuracy: 0.0437\n",
            "Epoch 7/30\n",
            "80/80 [==============================] - 62s 776ms/step - loss: 4.1874 - accuracy: 0.0547 - val_loss: 4.3286 - val_accuracy: 0.0234\n",
            "Epoch 8/30\n",
            "80/80 [==============================] - 62s 776ms/step - loss: 4.1440 - accuracy: 0.0504 - val_loss: 4.3244 - val_accuracy: 0.0344\n",
            "Epoch 9/30\n",
            "80/80 [==============================] - 62s 776ms/step - loss: 4.1214 - accuracy: 0.0539 - val_loss: 4.3168 - val_accuracy: 0.0344\n",
            "Epoch 10/30\n",
            "80/80 [==============================] - 61s 754ms/step - loss: 4.1249 - accuracy: 0.0609 - val_loss: 4.2639 - val_accuracy: 0.0437\n",
            "Epoch 11/30\n",
            "80/80 [==============================] - 63s 789ms/step - loss: 4.0835 - accuracy: 0.0562 - val_loss: 4.2397 - val_accuracy: 0.0312\n",
            "Epoch 12/30\n",
            "80/80 [==============================] - 66s 830ms/step - loss: 4.0201 - accuracy: 0.0754 - val_loss: 4.2717 - val_accuracy: 0.0437\n",
            "Epoch 13/30\n",
            "80/80 [==============================] - 67s 833ms/step - loss: 4.0293 - accuracy: 0.0715 - val_loss: 4.2466 - val_accuracy: 0.0500\n",
            "Epoch 14/30\n",
            "80/80 [==============================] - 61s 766ms/step - loss: 4.0282 - accuracy: 0.0707 - val_loss: 4.3424 - val_accuracy: 0.0484\n",
            "Epoch 15/30\n",
            "80/80 [==============================] - 62s 773ms/step - loss: 4.0094 - accuracy: 0.0773 - val_loss: 4.2874 - val_accuracy: 0.0516\n",
            "Epoch 16/30\n",
            "80/80 [==============================] - 62s 777ms/step - loss: 3.9850 - accuracy: 0.0824 - val_loss: 4.1739 - val_accuracy: 0.0594\n",
            "Epoch 17/30\n",
            "80/80 [==============================] - 62s 772ms/step - loss: 3.9574 - accuracy: 0.0863 - val_loss: 4.2313 - val_accuracy: 0.0453\n",
            "Epoch 18/30\n",
            "80/80 [==============================] - 61s 753ms/step - loss: 3.9279 - accuracy: 0.0898 - val_loss: 4.2294 - val_accuracy: 0.0391\n",
            "Epoch 19/30\n",
            "80/80 [==============================] - 60s 754ms/step - loss: 3.9439 - accuracy: 0.0809 - val_loss: 4.1955 - val_accuracy: 0.0656\n",
            "Epoch 20/30\n",
            "80/80 [==============================] - 61s 757ms/step - loss: 3.9103 - accuracy: 0.0840 - val_loss: 4.2252 - val_accuracy: 0.0484\n",
            "Epoch 21/30\n",
            "80/80 [==============================] - 61s 760ms/step - loss: 3.9139 - accuracy: 0.0801 - val_loss: 4.2644 - val_accuracy: 0.0562\n",
            "Epoch 22/30\n",
            "80/80 [==============================] - 61s 756ms/step - loss: 3.9168 - accuracy: 0.0742 - val_loss: 4.1822 - val_accuracy: 0.0578\n",
            "Epoch 23/30\n",
            "80/80 [==============================] - 61s 759ms/step - loss: 3.8625 - accuracy: 0.0887 - val_loss: 4.2501 - val_accuracy: 0.0594\n",
            "Epoch 24/30\n",
            "80/80 [==============================] - 61s 759ms/step - loss: 3.8703 - accuracy: 0.0961 - val_loss: 4.2482 - val_accuracy: 0.0516\n",
            "Epoch 25/30\n",
            "80/80 [==============================] - 61s 762ms/step - loss: 3.8485 - accuracy: 0.0859 - val_loss: 4.2982 - val_accuracy: 0.0578\n",
            "Epoch 26/30\n",
            "80/80 [==============================] - 61s 768ms/step - loss: 3.8472 - accuracy: 0.1035 - val_loss: 4.2744 - val_accuracy: 0.0437\n",
            "Epoch 27/30\n",
            "80/80 [==============================] - 61s 763ms/step - loss: 3.8352 - accuracy: 0.0965 - val_loss: 4.1997 - val_accuracy: 0.0734\n",
            "Epoch 28/30\n",
            "80/80 [==============================] - 60s 754ms/step - loss: 3.7933 - accuracy: 0.1031 - val_loss: 4.2216 - val_accuracy: 0.0469\n",
            "Epoch 29/30\n",
            "80/80 [==============================] - 61s 759ms/step - loss: 3.8075 - accuracy: 0.1078 - val_loss: 4.2487 - val_accuracy: 0.0422\n",
            "Epoch 30/30\n",
            "80/80 [==============================] - 61s 766ms/step - loss: 3.7929 - accuracy: 0.1059 - val_loss: 4.2167 - val_accuracy: 0.0547\n",
            "20/20 [==============================] - 11s 535ms/step - loss: 4.2167 - accuracy: 0.0547\n",
            "Accuracy: 5.47%\n",
            "Loss: 4.216727256774902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fvD-nOcYNV1"
      },
      "source": [
        "### **Prediction Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf7rg5MjYPph",
        "outputId": "d97d88f0-cf0e-4276-d297-bc32079171b6"
      },
      "source": [
        "results = model4.evaluate(test_generator, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 14s 555ms/step - loss: 4.2989 - accuracy: 0.0800\n",
            "test loss, test acc: [4.298933029174805, 0.07999999821186066]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}